import { GoogleGenAI, Modality } from '@google/genai';

// Lazy initialization to avoid crash on module load
let ai: GoogleGenAI | null = null;

function getAI(): GoogleGenAI {
  if (!ai) {
    const apiKey = process.env.API_KEY;
    console.log('üîë API Key check:', apiKey ? '‚úÖ Loaded' : '‚ùå Missing');
    console.log(
      'üîë API Key preview:',
      apiKey ? apiKey.substring(0, 20) + '...' : 'NONE'
    );
    if (!apiKey) {
      throw new Error(
        'API_KEY environment variable is not set. Please check your .env.local file.'
      );
    }
    console.log('üöÄ Initializing GoogleGenAI...');
    ai = new GoogleGenAI({ apiKey });
    console.log('‚úÖ GoogleGenAI initialized successfully');
  }
  return ai;
}

export async function transformImage(
  images: { data: string; mimeType: string }[],
  prompt: string
): Promise<string> {
  console.log('üé® Starting image transformation...');
  console.log('üìù Prompt:', prompt.substring(0, 50) + '...');

  const imageParts = images.map(image => ({
    inlineData: {
      data: image.data,
      mimeType: image.mimeType,
    },
  }));

  const textPart = {
    text: `IMPORTANT: Keep the original person or animal completely realistic and recognizable. Do NOT transform them into the character. Instead, dress them in a Halloween costume that matches this description: ${prompt}. The person/animal should look exactly like themselves, just wearing the costume. The final image must be hyper-realistic, resembling a high-resolution photograph with natural lighting, detailed textures, and lifelike features. The original face, body, and features must remain clearly visible and unchanged - only add costume elements like clothing, accessories, makeup, and props. Avoid any cartoonish, illustrative, or morphing effects.`,
  };

  console.log('üì° Sending request to Gemini API...');
  const response = await getAI().models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: [
      {
        parts: [...imageParts, textPart],
      },
    ],
    config: {
      responseModalities: [Modality.IMAGE, Modality.TEXT],
    },
  });

  console.log('‚úÖ Received response from Gemini API');
  console.log(
    'üì¶ Response structure:',
    JSON.stringify(response, null, 2).substring(0, 500)
  );

  // Check response structure
  if (!response) {
    console.error('‚ùå No response received');
    throw new Error('No response received from API');
  }

  if (!response.candidates || response.candidates.length === 0) {
    console.error('‚ùå No candidates in response');
    throw new Error('No candidates in API response');
  }

  if (!response.candidates[0]) {
    console.error('‚ùå First candidate is undefined');
    throw new Error('First candidate is undefined');
  }

  if (!response.candidates[0].content) {
    console.error('‚ùå No content in candidate');
    console.error('‚ùå Candidate:', JSON.stringify(response.candidates[0]));
    throw new Error('No content in API response candidate');
  }

  if (!response.candidates[0].content.parts) {
    console.error('‚ùå No parts in content');
    console.error(
      '‚ùå Content:',
      JSON.stringify(response.candidates[0].content)
    );
    throw new Error('No parts in API response content');
  }

  console.log('üì¶ Found', response.candidates[0].content.parts.length, 'parts');

  for (const part of response.candidates[0].content.parts) {
    console.log('üîç Checking part:', Object.keys(part));
    if (part.inlineData) {
      const base64ImageBytes: string = part.inlineData.data;
      const mimeType = part.inlineData.mimeType;
      console.log('üñºÔ∏è Image generated successfully!');
      return `data:${mimeType};base64,${base64ImageBytes}`;
    }
  }

  // Attempt to return text if the model explains why it couldn't generate an image
  const textResponse = response.text;
  if (textResponse) {
    console.error('‚ùå Model could not generate image:', textResponse);
    throw new Error(`Model could not generate image: ${textResponse}`);
  }

  console.error('‚ùå No image was generated by the model');
  throw new Error('No image was generated by the model.');
}

export async function generateVideoFromImage(
  base64ImageData: string,
  mimeType: string,
  prompt: string
): Promise<string> {
  console.log('üé¨ Starting video generation...');
  console.log('üìù Video prompt:', prompt.substring(0, 50) + '...');

  let operation = await getAI().models.generateVideos({
    model: 'veo-2.0-generate-001',
    prompt: `${prompt}. Make this image come alive for 5 seconds. Add subtle motion, like blinking or a gentle smile, while maintaining the character's look.`,
    image: {
      imageBytes: base64ImageData,
      mimeType: mimeType,
    },
    config: {
      numberOfVideos: 1,
    },
  });

  console.log('Video operation started:', operation);

  // Poll for completion
  while (!operation.done) {
    console.log('Polling for video result...');
    // Wait for 10 seconds before polling again
    await new Promise(resolve => setTimeout(resolve, 10000));
    operation = await getAI().operations.getVideosOperation({
      operation: operation,
    });
    console.log('Polling response:', operation);
  }

  if (operation.error) {
    console.error('Video generation failed:', operation.error);
    throw new Error(`Video generation failed: ${operation.error.message}`);
  }

  const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;

  if (!downloadLink) {
    console.error('No download link found in the video operation response.');
    throw new Error(
      'Video generation completed, but no download link was provided.'
    );
  }

  console.log('Video generated, download link:', downloadLink);

  // The download link needs the API key appended
  const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
  if (!response.ok) {
    throw new Error(`Failed to download video file: ${response.statusText}`);
  }

  const videoBlob = await response.blob();
  const videoUrl = URL.createObjectURL(videoBlob);

  console.log('Video downloaded and blob URL created:', videoUrl);
  return videoUrl;
}
